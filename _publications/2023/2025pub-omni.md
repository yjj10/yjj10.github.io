---
title: "OmniHallu: Unified Hallucination Detection for Cross-Modal Comprehension and Generation in Multimodal Large Language Models"
date: 2025-01-15 00:01:00 +0800
selected: true
pub: "Preparing for CVPR 2026 Submission"
pub_date: "2026"
abstract: >-
  Multimodal Large Language Models (MLLMs) have made significant progress but remain prone to hallucinations that contradict input semantics.  
  We introduce **OmniHallu**, a unified hallucination detection and evaluation framework designed to generalize across both comprehension and generation tasks, spanning text, image, video, and audio modalities.  
  OmniHallu integrates **OmniHallu-Bench**, a large-scale benchmark for cross-modal hallucination analysis, and a **multi-agent verification architecture** that decomposes and validates multimodal reasoning chains.  
  Extensive experiments demonstrate the frameworkâ€™s superior interpretability, generalization, and robustness, paving the way for trustworthy multimodal intelligence.
cover: /assets/images/photos/omnihallu.jpg
authors:
  - "Jianjiang Yang (First Author)"
  - "Peihang Li"
  - "Yanxiang Huang"
  - "Shanqing Xu"
  - "Lu Zhang"
  - "Junhao Dong"
  - "Dong Huang"
  - "Meng Luo"
links:
---

